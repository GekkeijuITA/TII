\documentclass[12pt]{article}
\usepackage[italian]{babel}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}

\geometry{margin=2cm}

\title{Proprietà dei Valori Attesi}
\author{Lorenzo Vaccarecci}
\date{5 Aprile 2024}

\graphicspath{{./Immagini/}}

\begin{document}
\maketitle
\section{Funzione di variabili casuali}
Il valore atteso di $g(X,Y)$, nel caso \textbf{discreto}, può essere calcolato come
\begin{equation*}
    \mathbb{E}[g(X,Y)]=\sum_{x}\sum_{y}g(x,y)p(x,y)
\end{equation*}
Se $g(X,Y)=X+Y$
\begin{equation*}
    \mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]
\end{equation*}
\subsection{Valore atteso di una variabile casuale binomiale}
Bernoulli con $\mathbb{E}[X_{i}]=p$ per tutti gli i
\begin{equation*}
    \mathbb{E}[X]=\mathbb{E}\left[\sum_{i=1}^{n}X_{i}\right]=np
\end{equation*}
\section{Media e varianza campionaria}
Se le $X_{i}$ per $i=1,\ldots,n$ sono variabili casuali identicamente e indipendentemente distribuite con valore atteso $\mu$ e varianza $\sigma^{2}$ definiamo la \textbf{media campionaria} come
\begin{equation*}
    m = \frac{1}{n}\cdot \sum_{i}X_{i}
\end{equation*}
\begin{equation*}
    \mathbb{E}[m]=\frac{1}{n}\cdot\sum_{i}\mathbb{E}[X_{i}] = \mu
\end{equation*}
\section{Covarianza}
Se $X$ e $Y$ sono indipendenti
\begin{equation*}
    \mathbb{E}[g(X)h(Y)]=\mathbb{E}[g(X)]\mathbb{E}[h(Y)]
\end{equation*}
La covarianza di due variabili casuali $X$ e$Y$ è definita come
\begin{equation*}
    Cov(X,Y)=\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
\end{equation*}
Se $X$ e $Y$ sono indipendenti allora
\begin{equation*}
    Cov(X,Y)=0
\end{equation*}
\end{document}